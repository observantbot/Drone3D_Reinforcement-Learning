{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "drone3D.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Control of a drone in 3-D using Reinforcement Learning"
      ],
      "metadata": {
        "id": "kj4VFT9HjjxI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries or Framework selection"
      ],
      "metadata": {
        "id": "zQZSp9Xtjcyv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afRCvedn_RI_"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!pip install stable-baselines[mpi]==2.10.0\n",
        "!pip install pybullet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Drone Envioronment"
      ],
      "metadata": {
        "id": "5DCVP72ahmgP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jznv1rlGaNFj"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import gym\n",
        "from gym import spaces\n",
        "import pybullet as p\n",
        "from PhysicsEngine import EnvPhysicsEngine, pqr_to_ang_vel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "                                     ______________________\n",
        "        x,y,z               ------> |                      |  ------> f1\n",
        "            R               ------> |                      |  ------> f2\n",
        "x_dot,y_dot,z_dot           ------> |      NN Model        |  ------> f3 \n",
        "phi_dot,theta_dot,psi_dot   ------> |                      |  ------> f4\n",
        "                                    |______________________|\n",
        "\n",
        "states (18 total)\n",
        "f1, f2, f3, f4 are the thrust for by each rotor respectively\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "class Drone3DEnv(gym.Env):\n",
        "\n",
        "    metadata = {'render.modes':['human']}\n",
        "\n",
        "    def __init__(self, drone, marker,\n",
        "                x_des =0, y_des= 0, z_des=5):\n",
        "\n",
        "        super(Drone3DEnv, self).__init__()\n",
        "\n",
        "        self.observation_space = spaces.Box(low=-1, high=1,\n",
        "                                            shape=(18,), \n",
        "                                            dtype=np.float32)\n",
        "\n",
        "        self.action_space = spaces.Box(low = -1, high = 1,\n",
        "                                       shape = (4,), \n",
        "                                       dtype=np.float32)\n",
        "\n",
        "        \n",
        "        self.drone = drone\n",
        "        self.marker = marker\n",
        "\n",
        "        self.pos_high = 5                       # m\n",
        "        self.lin_vel_high = 5                   # m/s\n",
        "        self.ang_high = np.deg2rad(75)          # It is allowed to attain upto 75 degree, but not more    \n",
        "        self.ang_vel_high = np.deg2rad(300)     # rad/sec\n",
        "\n",
        "        self.x_des          = x_des\n",
        "        self.y_des          = y_des\n",
        "        self.z_des          = z_des\n",
        "        self.phi_des        = 0\n",
        "        self.theta_des      = 0\n",
        "        self.psi_des        = 0\n",
        "        self.x_dot_des      = 0\n",
        "        self.y_dot_des      = 0\n",
        "        self.z_dot_des      = 0\n",
        "        self.phi_dot_des    = 0          \n",
        "        self.theta_dot_des  = 0          \n",
        "        self.psi_dot_des    = 0          \n",
        "        \n",
        "\n",
        "        self.action_high = 1.5*9.81/2  \n",
        "        # maximum thrust force by each rotor is mg\n",
        "        self.pe = EnvPhysicsEngine()\n",
        "\n",
        "\n",
        "    # current state--> current position, orientation, linear and angular velocities\n",
        "    def state(self):\n",
        "\n",
        "        x, y, z = self.pe.get_currentState()[0:3]\n",
        "\n",
        "        phi, theta, psi = self.pe.get_currentState()[3:6]\n",
        "        \n",
        "\n",
        "        x_dot, y_dot, z_dot = self.pe.get_currentState()[6:9]\n",
        "\n",
        "        p, q, r = self.pe.get_currentState()[9:]\n",
        "        phi_dot, theta_dot, psi_dot = pqr_to_ang_vel(p, q, r, theta, phi)\n",
        "\n",
        "        # error representation of state\n",
        "        state = self.abs_to_error_state(x, y, z, phi, theta, psi, \\\n",
        "                                        x_dot, y_dot, z_dot, \\\n",
        "                                        phi_dot, theta_dot, psi_dot)\n",
        "        return state\n",
        "    \n",
        "\n",
        "\n",
        "    # reward\n",
        "    def reward(self):\n",
        "\n",
        "        obs = self.state()\n",
        "        e_x, e_y, e_z = obs[:3]\n",
        "        phi, theta, psi = self.pe.rpy_from_rotmat(obs[3:12])\n",
        "                \n",
        "        e_x_dot, e_y_dot, e_z_dot = obs[12:15]\n",
        "        e_phi_dot, e_theta_dot, e_psi_dot = obs[15:18]\n",
        "\n",
        "        pos_err = (e_x**2 + e_y**2 + e_z**2)**0.5\n",
        "        orn_err = (phi**2 + theta**2 + psi**2)**0.5\n",
        "        lin_vel_err = (e_x_dot**2 + e_y_dot**2 + e_z_dot**2)**0.5\n",
        "        ang_vel_err = (e_phi_dot**2 + e_theta_dot**2 + e_psi_dot**2)**0.5\n",
        "        \n",
        "        reward = -(10*pos_err + 1*orn_err + 0.5*lin_vel_err + 0.5*ang_vel_err )\n",
        "\n",
        "        if self.done():\n",
        "            if (abs(e_x)>=1.5 or abs(e_y)>=1.5 or abs(e_z)>=1.5 or\\\n",
        "                  abs(phi)>=1 or abs(theta)>=1 or abs(psi)>=1 ):\n",
        "\n",
        "                print('******outbound condition***** e_x {:.2f} e_y {:.2f} e_z {:.2f} \\\n",
        "                        e_phi {:.2f} e_theta {:.2f} e_psi {:.2f}'\n",
        "                 .format(e_x, e_y, e_z, phi, theta, psi))\n",
        "                \n",
        "            else:\n",
        "                reward = 200.0\n",
        "                print('*******Desired Condition Achieved*********')\n",
        "\n",
        "        return float(reward/40.0)\n",
        "        \n",
        "    \n",
        "    # whether goal is achieved or not.\n",
        "    def done(self):\n",
        "        obs = self.state()\n",
        "        e_x, e_y, e_z = obs[:3]\n",
        "        phi, theta, psi = self.pe.rpy_from_rotmat(obs[3:12])\n",
        "\n",
        "        e_x_dot, e_y_dot, e_z_dot = obs[12:15]\n",
        "        e_phi_dot, e_theta_dot, e_psi_dot = obs[15:18]\n",
        "\n",
        "        if (abs(e_x)>=1.5 or abs(e_y)>=1.5 or abs(e_z)>=1.5 or\\\n",
        "                  abs(phi)>=1 or abs(theta)>=1 or abs(psi)>=1 ):  \n",
        "            # outbound condition; reset the environment          \n",
        "            return True\n",
        "\n",
        "        elif (abs(e_x)          <=0.01/self.pos_high and\\\n",
        "              abs(e_y)          <=0.01/self.pos_high and\\\n",
        "              abs(e_z)          <=0.01/self.pos_high and\\\n",
        "              abs(phi)          <=0.01/self.ang_high and\\\n",
        "              abs(theta)        <=0.01/self.ang_high and\\\n",
        "              abs(psi)          <=0.01/self.ang_high and\\\n",
        "              abs(e_x_dot)      <=0.01/self.lin_vel_high and\\\n",
        "              abs(e_y_dot)      <=0.01/self.lin_vel_high and\\\n",
        "              abs(e_z_dot)      <=0.01/self.lin_vel_high and\\\n",
        "              abs(e_phi_dot)    <=0.01/self.ang_vel_high and\\\n",
        "              abs(e_theta_dot)  <=0.01/self.ang_vel_high and\\\n",
        "              abs(e_psi_dot)    <=0.01/self.ang_vel_high  ):\n",
        "            # desired condition is achieved\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    # step\n",
        "    def step(self, action):\n",
        "\n",
        "        action_ = (action+1)*self.action_high\n",
        "\n",
        "        # '''for visualization purpose'''\n",
        "        # x, y, z, phi, theta, psi = self.pe.curr[:6]\n",
        "        # p.resetBasePositionAndOrientation(self.drone, [x, y, z],\n",
        "        #                     p.getQuaternionFromEuler([phi, theta, psi]))\n",
        "        # p.resetBasePositionAndOrientation(self.marker, \n",
        "        #                     [self.x_des,self.y_des,self.z_des],\n",
        "        #                     p.getQuaternionFromEuler([0,0,0]))\n",
        "        # p.stepSimulation()\n",
        "\n",
        "\n",
        "        '''execution'''\n",
        "        self.pe.stepSimulation(action_[0], action_[1], action_[2], action_[3])\n",
        "\n",
        "        state = self.state()\n",
        "        reward = self.reward()\n",
        "        done = self.done()\n",
        "        info = self.info()\n",
        "\n",
        "        return state, reward, done, info\n",
        "\n",
        "\n",
        "    # info\n",
        "    def info(self):\n",
        "        return {}\n",
        "\n",
        "\n",
        "    # reset the environment\n",
        "    def reset(self, obser=None):\n",
        "        # initializing quadcopter at random angle phi with angular vel phi_dot\n",
        "        x, y, z, phi, theta, psi,\\\n",
        "            x_dot, y_dot, z_dot, \\\n",
        "              phi_dot, theta_dot, psi_dot =  self.random_state_generator(obser)\n",
        "\n",
        "        # p.resetBasePositionAndOrientation(self.drone, [x,y,z],\n",
        "        #                                   p.getQuaternionFromEuler([phi, theta, psi]))\n",
        "\n",
        "        self.pe.reset(x, y, z, phi, theta, psi, x_dot, y_dot, z_dot, phi_dot, theta_dot, psi_dot)\n",
        "\n",
        "        # return state\n",
        "        state  = self.abs_to_error_state(x, y, z, phi, theta, psi, x_dot, y_dot,\n",
        "                                         z_dot, phi_dot, theta_dot, psi_dot)\n",
        "        \n",
        "        return state\n",
        "\n",
        "\n",
        "    def random_state_generator(self, obser=None):\n",
        "\n",
        "        if obser is None:\n",
        "            \n",
        "            x = random.uniform(-5, 5)\n",
        "            y = random.uniform(-5, 5)\n",
        "            z = random.uniform(0, 10)\n",
        "\n",
        "            phi     = random.uniform(-np.pi/3, np.pi/3)\n",
        "            theta   = random.uniform(-np.pi/3, np.pi/3)\n",
        "            psi     = random.uniform(-np.pi/3, np.pi/3)\n",
        "\n",
        "            x_dot  = random.uniform(-1, 1)\n",
        "            y_dot  = random.uniform(-1, 1)\n",
        "            z_dot  = random.uniform(-1, 1)\n",
        "\n",
        "            phi_dot   = random.uniform(-np.pi/6, np.pi/6)\n",
        "            theta_dot = random.uniform(-np.pi/6, np.pi/6)\n",
        "            psi_dot   = random.uniform(-np.pi/6, np.pi/6)\n",
        "             \n",
        "        else:\n",
        "            x,y,z, phi,theta,psi,\\\n",
        "              x_dot,y_dot,z_dot,\\\n",
        "                 phi_dot,theta_dot,psi_dot = obser\n",
        "\n",
        "        return x, y, z, phi, theta, psi,\\\n",
        "                 x_dot, y_dot, z_dot, \\\n",
        "                   phi_dot, theta_dot, psi_dot\n",
        "\n",
        "\n",
        "    def abs_to_error_state(self, x, y, z, phi, theta,\n",
        "                             psi, x_dot, y_dot, z_dot,\n",
        "                             phi_dot, theta_dot, psi_dot):\n",
        "\n",
        "        # assuming maximum quadcopter angle would be 90 degree\n",
        "        e_x = (x - self.x_des) / self.pos_high\n",
        "        e_y = (y - self.y_des) / self.pos_high\n",
        "        e_z = (z - self.z_des) / self.pos_high\n",
        "\n",
        "        R = self.pe.rotationalmat(phi, theta, psi)\n",
        "\n",
        "        e_x_dot = (x_dot - self.x_dot_des) / self.lin_vel_high\n",
        "        e_y_dot = (y_dot - self.y_dot_des) / self.lin_vel_high\n",
        "        e_z_dot = (z_dot - self.z_dot_des) / self.lin_vel_high\n",
        "\n",
        "        e_phi_dot = (phi_dot - self.phi_dot_des) / self.ang_vel_high\n",
        "        e_theta_dot = (theta_dot - self.theta_dot_des) / self.ang_vel_high\n",
        "        e_psi_dot = (psi_dot - self.psi_dot_des) / self.ang_vel_high\n",
        "\n",
        "        return np.array([e_x, e_y, e_z,   \\\n",
        "                        R[0], R[1], R[2], \\\n",
        "                        R[3], R[4], R[5], \\\n",
        "                        R[6], R[7], R[8], \\\n",
        "                        e_x_dot, e_y_dot, e_z_dot,\\\n",
        "                        e_phi_dot, e_theta_dot, e_psi_dot])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Integration with pybullet simulation"
      ],
      "metadata": {
        "id": "CrrX-mdghsyM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0c05mMsaNB_"
      },
      "source": [
        "import pybullet as p\n",
        "import pybullet_data\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def init_simulation(render = False):\n",
        "\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print('optimized...')\n",
        "\n",
        "    if render:\n",
        "        physicsClient = p.connect(p.GUI)\n",
        "    else:\n",
        "        physicsClient = p.connect(p.DIRECT)\n",
        "        \n",
        "    p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
        "    p.setGravity(0,0,-9.81)\n",
        "    p.setTimeStep(0.01)\n",
        "\n",
        "    '------------------------------------'\n",
        "    # drone\n",
        "    drone = p.loadURDF('/content/drive/MyDrive/drone_URDF/drone.urdf')\n",
        "\n",
        "    # marker at desired point\n",
        "    sphereVisualId = p.createVisualShape(shapeType=p.GEOM_SPHERE,\n",
        "                                        radius = 0.05,\n",
        "                                        rgbaColor= [1, 0, 0, 1])\n",
        "    marker = p.createMultiBody(baseMass=0.0, baseCollisionShapeIndex=-1,\n",
        "                    baseVisualShapeIndex=sphereVisualId, basePosition=[0, 0, 8.0],\n",
        "                    useMaximalCoordinates=False)\n",
        "    '-------------------------------------'\n",
        "\n",
        "    return drone, marker\n",
        "\n",
        "def end_simulation():\n",
        "    p.disconnect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensure our Custom Enviornment matches OpenAI gym interface"
      ],
      "metadata": {
        "id": "sy75DFVBhy4o"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvoDVlyNaM_O"
      },
      "source": [
        "# ensure custom environment matches gym env interface \n",
        "from stable_baselines.common.env_checker import check_env\n",
        "\n",
        "drone, marker = init_simulation()\n",
        "env = Drone3DEnv(drone, marker)\n",
        "print('obs_space',env.observation_space)\n",
        "print('action_spc: ', env.action_space)\n",
        "\n",
        "for i in range(10):\n",
        "    print(env.action_space.sample())\n",
        "\n",
        "check_env(env, warn=True)\n",
        "end_simulation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training of SAC model using Stable Baselines"
      ],
      "metadata": {
        "id": "EhNP9-ONiJj5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J6tpOEAaM82"
      },
      "source": [
        "# train a DDPG algorithm based model using Stable Baselines library from open AI.\n",
        "from stable_baselines.sac.policies import MlpPolicy\n",
        "from stable_baselines import SAC\n",
        "\n",
        "\n",
        "drone, marker = init_simulation()\n",
        "env = Drone3DEnv(drone, marker)\n",
        "\n",
        "model = SAC(MlpPolicy, env, verbose=1)\n",
        "\n",
        "for i in range(1, 51):\n",
        "  save_path = \"/content/drive/MyDrive/drone3D/drone\" + str(i) + \".zip\"\n",
        "  if i==1:\n",
        "    model.learn(total_timesteps=10000)\n",
        "    # at every 10000 time steps, we will save our model\n",
        "    model.save(save_path)\n",
        "  else:\n",
        "    del model\n",
        "    model = SAC.load(prev_path, env)\n",
        "    model.learn(total_timesteps=10000)\n",
        "    model.save(save_path)\n",
        "  prev_path = save_path\n",
        "\n",
        "print('done')\n",
        "\n",
        "end_simulation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking which model is working the best with manually chosen games"
      ],
      "metadata": {
        "id": "thcaZcX7iTT8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFpy12_rogQ4"
      },
      "source": [
        "from stable_baselines import SAC\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "drone, marker = init_simulation(render = False)\n",
        "env = Drone3DEnv(drone, marker)\n",
        "\n",
        "\n",
        "def run_agent(model):\n",
        "    obs = env.reset()\n",
        "    print('initial state: ', obs)\n",
        "    t = 0\n",
        "    for i in range(500):\n",
        "        action = model.predict(obs)\n",
        "        obs, reward, done, _ = env.step(action[0])\n",
        "        # time.sleep(0.01)\n",
        "        t += 0.01\n",
        "        if done:\n",
        "            if reward>4.5:\n",
        "                print('***********',t)\n",
        "            else:\n",
        "                print('***********', 5)     # evaluation metric\n",
        "                t = 5\n",
        "            return t\n",
        "    return t\n",
        "\n",
        "t1 = []\n",
        "game = []\n",
        "for i in range(1,51):\n",
        "    filepath = '/content/drive/MyDrive/drone3D/drone'+ str(i) + '.zip'\n",
        "    model = SAC.load(filepath)\n",
        "    t = run_agent(model=model)\n",
        "    t1.append(t)\n",
        "    game.append(i)\n",
        "\n",
        "\n",
        "d = {'game': game, 'time': t1}\n",
        "df = pd.DataFrame(d).to_csv('/content/drive/MyDrive/drone3D/game.csv')\n",
        "\n",
        "\n",
        "end_simulation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run our Trained Agent on random games"
      ],
      "metadata": {
        "id": "lyPD5Kx-i5uQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTuoJMvCaM6r"
      },
      "source": [
        "# run our best trained agent on random games\n",
        "from stable_baselines import SAC\n",
        "import time\n",
        "\n",
        "drone, marker = init_simulation(render = False)\n",
        "env = Drone3DEnv(drone, marker)\n",
        "model = SAC.load('/content/drive/MyDrive/drone3D/sac_stablebaseline_1.zip')    # path to the best model\n",
        "\n",
        "\n",
        "obs = env.reset()\n",
        "print('initial state: ', obs)\n",
        "\n",
        "for _ in range(10000):\n",
        "    action = model.predict(obs)\n",
        "    obs, rew, done, info = env.step(action[0])\n",
        "    time.sleep(0.01)\n",
        "    if done:\n",
        "        env.reset()\n",
        "\n",
        "end_simulation()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvmq5bS9aM4M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8nHI-7__fXi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56TSKXDx_fRu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}